{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab09.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "title",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# Lab 09: Random Variables\n",
    "In this lab, you will:\n",
    "\n",
    "1. Explore properties of random variables using the example of a binomial distribution.\n",
    "1. Verify the Central Limit Theorem (CLT) using simulations. \n",
    "1. Examine if the \"sample maximum\" is a biased estimator for the true maximum of a population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Due Date\n",
    "\n",
    "The on-time deadline is **Tuesday, October 31st at 11:59 PM PT** (Happy Halloween!). Please read the syllabus for the grace period policy. No late submissions beyond the grace period will be accepted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab Walk-Through\n",
    "In addition to the lab notebook, we have also released a prerecorded walk-through video of the lab. We encourage you to reference this video as you work through the lab. Run the cell below to display the video.\n",
    "\n",
    "**Note**: The walkthrough video is partially recorded from Spring 2023. There may be slight inconsistencies between the version you are viewing and the version used in the recording, but content is identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo(\"_K7OvmRbb5w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaboration Policy\n",
    "Data science is a collaborative activity. While you may talk with others about this assignment, we ask that you **write your solutions individually**. If you discuss the assignment with others, please **include their names** in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Collaborators:** *list names here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "setup",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell to set up your notebook\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "from IPython.display import FileLink, FileLinks\n",
    "FileLink('path_to_file/filename.extension')\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "sns.set_context(\"talk\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(2023) # Do not change this line; this sets the pseudorandomness of the autograder.\n",
    "\n",
    "from IPython.display import display, Latex, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "intro",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<br/><br/>\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "# Question 1: Probability with Binomial Random Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "## Question 1a: Loading the Data\n",
    "\n",
    "The Berkeley Half Marathon is an annual weekend-long race here in Berkeley. \n",
    "\n",
    "We want to understand how many participants in this year’s race also participated in the previous year's race. To accomplish this, we collect a sample of this year’s participants.\n",
    "\n",
    "Let's first assume that we have access to the official data so we can simulate the potential result we might get (**in practice we don't!**). The dataset `marathon.csv` includes information for **all racers** who registered for the Berkeley Half Marathon. In other words, the dataset represents our **full population**.\n",
    "\n",
    "* The `Bib Number` of each participant (i.e., racer) is in order of registration — integers from $1$ to the total unknown number of participants. \n",
    "* The column `Race Type` denotes the type of race a participant is in.\n",
    "* The column `Experienced` denotes if a participant participated in the race in the previous year.\n",
    "* The column `Dog Lover` denotes if a participant is a dog lover.\n",
    "\n",
    "Load the dataset `marathon.csv` into the `DataFrame` `marathon` and assign `true_prop` to the true proportion of experienced racers. \n",
    "\n",
    "**Hint:** The **true proportion** of experienced racers is the proportion of experienced racers in the *population*. We term numerical functions of the population, such as the true proportion of experienced racers, as **population parameters**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "marathon = ...\n",
    "display(marathon.head())\n",
    "true_prop = ...\n",
    "print(f\"The true proportion of experienced racers in the population of size {len(marathon)} is {np.round(true_prop, 4)}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Suppose that you have access to the official roster and are able to collect a Simple Random Sample (SRS) of 100 racers. You decided to use the proportion of experienced racers in this smaller *sample* as an **estimate** of the true proportion of experienced racers in the full *population*. Let's denote this true proportion as $p$.\n",
    "\n",
    "\n",
    "How would a sample proportion compare to the true proportion? Suppose we take a simple random sample of size $n$. For an individual $i \\in \\{1, 2, \\dots, n\\}$ in our sample, we define $X_i$ to be a random variable indicating if individual $i$ is experienced or not. That is, if individual $i$ is experienced, $X_i = 1$, otherwise, $X_i = 0$. Then we can define the sample proportion as the fraction of experienced racers in the sample. The sample proportion $\\hat{p}$ is therefore also the mean of the sample.\n",
    "\n",
    "$$\\hat{p} = \\text{sample proportion} = \\frac{1}{n}\\sum_{i=1}^{\\text{n}} X_i$$\n",
    "\n",
    "Note that **sample proportion** is a numerical function of the sample, so it is also a (sample) statistic. As a reminder, sample statistics are random variables, due to the randomness of the samples. \n",
    "\n",
    "\n",
    "For the remainder of the lab, we will assume that the true population is large enough to simplify the sample as **a random sample with replacement.** Under this assumption, $X_i$’s are i.i.d (independent and identically distributed). Each $X_i$ follows a Bernoulli distribution with probability $p$ that a racer is experienced (i.e. $P(X_i = 1) = p$). Then, the sample proportion $\\hat{p}$ is a scaled Binomial random variable with expectation $\\mathbb{E}[\\hat{p}] = p$ and variance $\\text{Var}(\\hat{p}) = \\frac{p(1-p)}{n}$.\n",
    "\n",
    "As a reminder, we can show that $\\mathbb{E}[\\hat{p}] = p$ via linearity of expectation:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[\\hat{p}] = \\mathbb{E}[\\frac{1}{n}\\sum_{i=1}^{\\text{n}} X_i] = \\frac{1}{n}\\sum_{i=1}^{\\text{n}} \\mathbb{E}[X_i] = \\frac{1}{n}\\sum_{i=1}^{\\text{n}} p = \\frac{np}{n} = p\n",
    "$$\n",
    "\n",
    "and $\\text{Var}(\\hat{p}) = \\frac{p(1-p)}{n}$ via additivity of variance in independent variables:\n",
    "\n",
    "$$\n",
    "\\text{Var}(\\hat{p}) = \\text{Var}(\\frac{1}{n}\\sum_{i=1}^{\\text{n}} X_i) = \\frac{1}{n^2}\\sum_{i=1}^{\\text{n}} \\text{Var}(X_i) = \\frac{1}{n^2}\\sum_{i=1}^{\\text{n}} p(1-p) = \\frac{p(1-p)}{n}\n",
    "$$\n",
    "\n",
    "In the remainder of this question, let's confirm these statistics through simulation.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 1b: Expected Proportion\n",
    "\n",
    "The expressions above give us the expectation and variance for the proportion of experienced racers if we apply probability theory. Do these results hold true if we actually simulate the proportion of experienced racers on random samples?”\n",
    "\n",
    "Run 5000 independent simulations to compute the **proportion of experienced racers** in simulated samples of size $n = 100$, each generated uniformly at random from the true population `marathon`. You may assume that the true population is large enough such that the sample is a random sample with replacement. Assign `samples` to an array with 5000 elements, each of which is the proportion of experienced racers in that simulated sample. Also, assign `simulated_mean` and `simulated_var` to the mean and variance of the simulated proportions, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "samples = ...\n",
    "simulated_mean = ...\n",
    "simulated_var = ...\n",
    "\n",
    "print(f\"[Mean]     Simulated: {simulated_mean:.5f}   Theoretical: {true_prop:.5f}\")\n",
    "print(f\"[Variance] Simulated: {simulated_var:.5f}   Theoretical: {true_prop*(1-true_prop)/100:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "What is a better way to support racers than passing out dog photos? :-) You decide to take a sample of size $n = 100$, where each racer will receive 1 dog photo if they are an experienced racer, 3 dog photos if they love dogs, and 4 dog photos if they are both an experienced racer and love dogs. What is the expected number of photos you need to print? \n",
    "\n",
    "Again, assume that the true population is large enough such that the sample is a random sample with replacement to simplify the problem, and that whether a racer loves dogs and whether the racer participated in the previous year are independent. Let $D$ be the number of dog photos that need to be printed. Here, we picked $D$ to refer to **d**og photos. More generally, when picking letters for random variables, it is good practice to try and pick something informative and unambiguous. \n",
    "\n",
    "We can then find the **expected number of photos, $\\mathbb{E}(D)$** as follows: \n",
    "$$\\mathbb{E}(D) = \\large 100 \\cdot p + 100 \\cdot 3 \\cdot q,$$ \n",
    "where $p$ is the true proportion of experienced racers and $q$ is the true proportion of dog lovers. This result follows from the linearity of expectation:\n",
    "\n",
    "$$\\mathbb{E}[aX+bY] = a \\mathbb{E}[X] + b\\mathbb{E}[Y].$$\n",
    "\n",
    "The variance of the number of photos is:\n",
    "$$\\text{Var} (D) = \\large 100 \\cdot p (1- p)+ 100 \\cdot 3^2 \\cdot q (1- q),$$\n",
    "which follows from the properties of variance and that the two samples are independent: \n",
    "\n",
    "$$\\text{Var}(aX+bY) = a^2\\text{Var}(X) + b^2\\text{Var}(Y) + 2 \\cdot a \\cdot b \\text{Cov}(X, Y) = a^2\\text{Var}(X) + b^2\\text{Var}(Y).$$\n",
    "\n",
    "See the video walkthrough for a full derivation of these results.\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 1c: Expectation and Variance of Linear Combinations of Random Variables\n",
    "\n",
    "Confirm this result through simulation. Run 5000 independent simulations, where each simulation finds the number of **photos** needed for a sample of size $n = 100$ racers, selected uniformly at random (with replacement) from the true population `marathon`.  Assign `photo_samples` to an array with 5000 elements, each of which is the number of **photos** needed for the simulated sample. \n",
    "\n",
    "**Note:** We have computed `prop_dog_lover`, the true proportion of dog lover racers for you so that you can verify that your simulated statistics match the theoretical statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prop_dog_lover = np.mean(marathon[\"Dog Lover\"])\n",
    "\n",
    "photo_samples = []\n",
    "...\n",
    "\n",
    "simulated_photos_mean = np.mean(photo_samples)\n",
    "simulated_photos_var = np.var(photo_samples)\n",
    "\n",
    "\n",
    "print(f\"[Mean]     Simulated: {simulated_photos_mean:.5f}    Theoretical: {(true_prop + 3*prop_dog_lover)*100:.5f}\")\n",
    "print(f\"[Variance] Simulated: {simulated_photos_var:.5f}   Theoretical: {100*true_prop*(1-true_prop) + 900*prop_dog_lover*(1-prop_dog_lover):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "# Question 2: Central Limit Theorem\n",
    "\n",
    "The Central Limit Theorem states that the distribution of the sample mean will converge to a normal distribution as the sample size ($n$) goes to infinity. That means that if we collected enough samples from the population, calculated the proportion of experienced racers (which is a sample mean) for each sample, and viewed a histogram of the proportions, we would see a normal distribution!\n",
    "\n",
    "Let's see this in action!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 2a\n",
    "Complete the function `simulate`. The function `simulate` takes in one argument (`sample_size`: the size of the sample) and returns a list of length 5000 where each element is the proportion of experienced racers in a random sample of size `sample_size`. \n",
    "\n",
    "Then, use `simulate` to run 5000 independent simulations, where each simulation finds the proportion of **experienced racers** in a sample of size of 100, 500, and 1000 selected uniformly at random from the true population `marathon`. You may assume that the true population is large enough such that the sample is a random sample with replacement (note that in reality, our population is finite in size about 50k; this approximation becomes more inaccurate as our sample size grows larger). You should assign `samples100`, `samples500`, and `samples1000` each to arrays of 5000 elements with proportions of experienced racers of sample sizes **100**, **500**, and **1000**, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def simulate(sample_size):\n",
    "    ...\n",
    "\n",
    "samples100 = ...\n",
    "samples500 = ...\n",
    "samples1000 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 2b\n",
    "\n",
    "Recall that if a random variable follows a normal distribution with mean $\\mu$ and variance $\\sigma^2$, then its Probability Density Function (pdf) is\n",
    "$$\\large\n",
    "f(x) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp\\left(-\\frac{(x - \\mu)^2}{2  \\sigma ^2} \\right)\n",
    "$$\n",
    "\n",
    "Complete the function `gaussian` which returns the pdf of a normal distribution with mean `mean`, and variance of `var`, computed at values `x`. Pay attention to the order of operations and add parentheses accordingly - the solution presented in the lab walkthrough video is missing a pair, so you will need to modify the solution slightly!\n",
    "\n",
    "**Hint:** This is very similar to `gaussian_kernel` from Lab 04!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gaussian(mu, var, x):\n",
    "    \"\"\"\n",
    "    Compute the Gaussian density at value x.\n",
    "\n",
    "    Args:\n",
    "        mu: the mean/center of the Gaussian distribution.\n",
    "        var: variance of the Gaussian distribution.\n",
    "        x: observation.\n",
    "\n",
    "    Returns:\n",
    "        The density at value x.\n",
    "    \"\"\"    \n",
    "    ...\n",
    "\n",
    "gaussian(0, 1, np.array([-1, 0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 2c\n",
    "\n",
    "We are ready to demonstrate the Central Limit Theorem visually by comparing simulated distributions of sample means to the normal distribution. We have provided the skeleton code of an interactive plot. Fill in the blanks below using the `simulate` and `gaussian` functions from previous parts of this question.\n",
    "\n",
    "Then, in the cell below, describe the mean and spread of the sampling distribution and how they change as you increase the value of `sample_size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "def f(sample_size):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    # Generate the simulated proportions\n",
    "    sim_samples = ...\n",
    "    # Make a histogram plot of the simulated proportions. Set density to True and edgecolor to \"none\"\n",
    "    ...\n",
    "    x = np.linspace(0, 1, 1001)\n",
    "    # We provided the mean and variance for you. If you are interested in knowing how to calculate these, take Data 140!\n",
    "    mean = true_prop\n",
    "    var = true_prop*(1-true_prop)/sample_size\n",
    "    # Compute the pdf of the normal distribution of mean `mean` and variance `var` at locations x\n",
    "    y = ...\n",
    "    plt.plot(x, y, linewidth=1)\n",
    "    plt.xlim(0, 0.6);\n",
    "    plt.ylim(0, 35);\n",
    "    plt.show()\n",
    "interact(f, sample_size=(10, 1000, 10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "# Question 3: Estimator for Population Max\n",
    "\n",
    "\n",
    "Now suppose that we do not have access to the official roster; instead, we only have one sample. Without the official roster, we do not know the population and therefore do not know the total number of racers. However, we still want to estimate the total racers given an observed sample so we can prepare a dog photo for everyone. That is, we want to find an estimator for the **population maximum**.\n",
    "\n",
    "Recall that the `Bib Number` of each participant (i.e., racer) is in order of registration—integers from $1$ to the total unknown number of participants. You decide to construct a sample by recording the bib number of every racer you see on the street in a given time period and use the maximum bib number in your sample as an estimator for the true maximum bib number (that is, the total number of participants, assuming everyone who registered participated). Assume that a racer's bib number has no relation to their racing experience so that you are equally likely to see any of the bib numbers in your sample.\n",
    "\n",
    "**Is the sample maximum a good estimator for the population maximum?** We'll use simulation to explore the answer to this question in this part of the lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 3a\n",
    "\n",
    "Let's first assume that we have access to the total number of participants (again, in practice we don't!). Find the **true population maximum** and assign it to `true_max`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_max = ...\n",
    "true_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to see the summary statistics of Bib Number; no further action is needed.\n",
    "marathon.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the above output to quickly check and see if the value you assigned to `true_max` aligns with what you find in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 3b\n",
    "\n",
    "How would a sample maximum compare to the true maximum? Suppose we draw a sample of size $n$ with replacement from the population. We denote the bib number of individual $i$ in the sample as $B_i$. We will have $n$ i.i.d. random variables: $B_1, B_2, \\dots, B_n$. Define the **sample max** as the maximum value of the sample.\n",
    "\n",
    "$$\\text{sample max} = \\max (B_1, \\dots, B_n)$$\n",
    "\n",
    "\n",
    "Recall from [Data 8](https://inferentialthinking.com/chapters/10/3/Empirical_Distribution_of_a_Statistic.html) that we can get the empirical distribution of a statistic by **simulating**, or repeatedly sampling from the population.\n",
    "Suppose we compute the sample max as the **maximum bib number from observing the bib numbers of $n = 200$ random racers**. By repeating this process for many randomly selected samples, we get a simulated distribution of the sample max statistic.\n",
    "\n",
    "Assign `sample_maxes` to an array that contains 5000 simulated sample maxes from samples of size $n = 200$, each sampled randomly **with replacement** from the population `marathon`. (Side note: We sample with replacement because while it suggests that we could see the same racer multiple times in our sample, it allows us to assume each individual in our sample is drawn i.i.d. from the population.)\n",
    "\n",
    "Some useful functions: `df.sample` ([link](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html)), `np.random.choice` ([link](https://numpy.org/doc/stable/reference/random/generated/numpy.random.choice.html)). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2_code",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "sample_maxes = ...\n",
    "for i in range(5000):\n",
    "    sample = ...\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Question 3c\n",
    "\n",
    "Plot the empirical distribution of the sample maximum that you generated in Question 3b. Your plot should look like the below plot. It should include both the average sample maximum and the true population maximum as vertical lines.\n",
    "\n",
    "<img src='images/sample_max_dist.png' width=\"600px\" />\n",
    "\n",
    "Visualization/plotting tips:\n",
    "* To plot a vertical line with specific linestyles, see the `plt.axvline` [documentation](https://matplotlib.org/3.5.1/api/_as_gen/matplotlib.pyplot.axvline.html).\n",
    "* To include a label in the legend, pass in `label=...` to the plot that you'd like to label ([example](https://matplotlib.org/3.5.1/gallery/pyplots/axline.html#sphx-glr-gallery-pyplots-axline-py)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = [10, 6])\n",
    "bins = np.linspace(49000, 50750, 25) # For your plot\n",
    "\n",
    "avg_sample_maxes = ...\n",
    "...\n",
    "\n",
    "plt.legend();     # Show legend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "</br>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 3d\n",
    "\n",
    "Recall from Lecture 16 that an **unbiased estimator** is one where the expected value of the estimator is the parameter. For example, the sample mean $\\bar{X}_n$ is an unbiased estimator of the population mean $\\mu$ because $\\mathbb{E}[\\bar{X}_n] = \\mu$ by linearity of expectation.\n",
    "\n",
    "Based on your analysis in Question 3c, assign `q3d` to the most correct option out of the following; then in the second cell, **explain your choice.**\n",
    "\n",
    "1. The sample maximum is an unbiased estimator of the population maximum.\n",
    "1. The sample maximum overestimates the population maximum.\n",
    "1. The sample maximum underestimates the population maximum.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q3d = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Food for thought (optional):\n",
    "\n",
    "What if instead of the sample max, we use another estimator, $2 \\bar{X_n} - 1$?  This is a common approach for this kind of uniform data; if you are interested, simulate and visualize the results for this estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your optional visualization here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "finish",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<br/><br/>\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Congratulations! You are finished with Lab 09!\n",
    "\n",
    "Here at Data 100, we believe everyone deserves dog photos, even if you haven't run the Berkeley Half Marathon. We added in a couple extra to make up for the profound lack of dog photos at the end of A2. Here's a collage of Roxy, Ludo, and Nori!\n",
    "\n",
    "<img src='images/roxy_1.jpeg' width=\"280px\" /> <img src='images/roxy_2.jpeg' width=\"245px\" /> \n",
    "\n",
    "<img src='images/ludo_1.jpeg' width=\"200px\" /> <img src='images/ludo_2.jpeg' width=\"200px\" />\n",
    "\n",
    "<img src='images/Nori_1.jpg' width=\"190px\" /> <img src='images/Nori_2.jpg' width=\"399px\" />\n",
    "\n",
    "<img src='images/Nori_3.jpg' width=\"270px\" /> <img src='images/Nori_4.jpg' width=\"162px\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False, run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1a": {
     "name": "q1a",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> marathon.shape == (50732, 4)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(true_prop, 0.24897500591342742)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1b": {
     "name": "q1b",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isclose(simulated_mean, true_prop, atol=1e-2)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(simulated_var, true_prop*(1-true_prop)/100, atol=1e-4)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1c": {
     "name": "q1c",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isclose(simulated_photos_mean, (true_prop + 3*prop_dog_lover)*100, atol=1)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(simulated_photos_var, 100*true_prop*(1-true_prop) + 900*prop_dog_lover*(1-prop_dog_lover), atol=5)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2a": {
     "name": "q2a",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isclose(np.mean(samples100), 0.24898, atol=1e-2)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(np.mean(samples500), 0.24898, atol=1e-2)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(np.mean(samples1000), 0.24898, atol=1e-2)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2b": {
     "name": "q2b",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.allclose(gaussian(0, 1, np.array([-1, 0, 1])), np.array([0.24197072, 0.39894228, 0.24197072]))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.allclose(gaussian(1, 2, np.array([-1, 0, 1])), np.array([0.10377687, 0.21969564, 0.28209479]))\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3a": {
     "name": "q3a",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> true_max == 50732\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3b": {
     "name": "q3b",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> len(sample_maxes) == 5000\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.mean(sample_maxes) <= true_max\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.max(sample_maxes) <= true_max\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3d": {
     "name": "q3d",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> q3d in [1, 2, 3]\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> q3d == 3\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
