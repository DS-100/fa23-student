{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab03.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "intro",
     "locked": true,
     "schema_version": 2,
     "solution": false
    },
    "tags": []
   },
   "source": [
    "### Content Warning\n",
    "This lab includes an analysis of crime in Berkeley. If you feel uncomfortable with this topic, **please contact your TA or the instructors, or reach out via the Fall 2023 extenuating circumstances form.**\n",
    "\n",
    "\n",
    "# Lab 3: Data Cleaning and EDA\n",
    "\n",
    "In this lab, you will be working on visualizing a dataset from the City of Berkeley containing data on calls to the Berkeley Police Department. Information about the dataset can be found [at this link](https://data.cityofberkeley.info/Public-Safety/Berkeley-PD-Calls-for-Service/k2nh-s5h5).\n",
    "\n",
    "\n",
    "To receive credit for a lab, answer all questions correctly and submit before the deadline.\n",
    "\n",
    "**The on-time deadline is Tuesday, September 19th, at 11:59 PM. Please read the syllabus for the grace period policy. No late submissions beyond the grace period will be accepted.**\n",
    "\n",
    "### Lab Walkthrough\n",
    "In addition to the lab notebook, we have also released a prerecorded walkthrough video of the lab. This playlist includes a walkthrough for every question in the lab. We encourage you to reference this video as you work through the lab. Run the cell below to display the video.\n",
    "<br>\n",
    "\n",
    "**Note:** This video was recorded in Spring 2022. There may be slight inconsistencies between the version you are viewing and the version used in the recording, but the content is largely identical. The key difference is that we are using the most updated 2022 dataset for the Berkeley crime data, not the 2021 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo(\"LcIXTx49o2A\", list = 'PLQCcNQgUcDfrG1xueBsgwDy0x5vQmi5j0', listType = 'playlist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaboration Policy\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with others about this assignment, we ask that you **write your solutions individually**. If you discuss the assignment with others, please **include their names** in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Collaborators:** *list names here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "setup",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "### Setup\n",
    "\n",
    "In this lab, we'll perform Exploratory Data Analysis and learn some preliminary tips for working with `matplotlib` (a Python plotting library). In the cell below, we configure a custom default figure size. Virtually every default aspect of `matplotlib` [can be customized](https://matplotlib.org/users/customizing.html). `matplotlib` will formally be taught in lectures 7 and 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "imports",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "part1",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<br/>\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "# Part 1: Acquire the Data\n",
    "\n",
    "Here, we start by acquiring the data that this lab is based on. **Please don't worry about understanding all the code in this section**; the steps shown here are out of scope and provided here for student interest!\n",
    "\n",
    "**1. Obtain data**<br/>\n",
    "To retrieve the dataset, we will use the `ds100_utils.download_lab3_data` utility, a helper function that Data 100 staff created. You can see how this is implemented by opening the file `ds100_utils.py` on the left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell to download the data, no further action is needed.\n",
    "from ds100_utils import download_lab3_data\n",
    "\n",
    "dest_path = download_lab3_data()\n",
    "print(f'Located at {dest_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "unzip-data-1",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "**2. Unzip file**<br/>\n",
    "We will now directly unzip the ZIP archive and start working with the uncompressed files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to unzip the data, no further action is needed.\n",
    "my_zip = zipfile.ZipFile(dest_path, 'r')\n",
    "my_zip.extractall('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no single right answer regarding whether to work with compressed files in their compressed state or to uncompress them on disk permanently. For example, if you need to work with multiple tools on the same files or write many notebooks to analyze them—and they are not too large—it may be more convenient to uncompress them once. But you may also have situations where you find it preferable to work with the compressed data directly.  \n",
    "\n",
    "`Python` gives you tools for both approaches, so it can be helpful to know how to perform both tasks in order to choose the one that best suits the problem at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q0",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "**3. View files**\n",
    "\n",
    "Now, we'll use the `os` package to list all files in the `data` directory. `os.walk()` recursively traverses the directory, and `os.path.join()` creates the full pathname of each file.\n",
    "\n",
    "If you're interested in learning more, check out the `Python3` documentation pages for `os.walk` ([link](https://docs.python.org/3/library/os.html#os.walk)) and `os.path.join` ([link](https://docs.python.org/3/library/os.path.html#os.path.join)).\n",
    "\n",
    "We use `Python3` [format strings](https://docs.python.org/3/tutorial/inputoutput.html) to nicely format the printed variables `dpath` and `fpath`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell to view the content in the zip file, no further action is needed.\n",
    "import os\n",
    "\n",
    "for root, directories, filenames in os.walk('data'):\n",
    "    # first, print out all directories\n",
    "    for directory in directories:\n",
    "        dpath = os.path.join(root, directory)\n",
    "        print(f\"d {dpath}\")\n",
    "        \n",
    "    # next, print out all files\n",
    "    for filename in filenames:  \n",
    "        fpath = os.path.join(root,filename)\n",
    "        print(f\"  {fpath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "explore-0",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "In this Lab, we'll be working with the `Berkeley_PD_-_Calls_for_Service_2022.csv` file. Feel free to check out the other files, though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "# Part 2: Clean and Explore the Data\n",
    "\n",
    "Let's now load the CSV file we have into a `DataFrame`, and start exploring the data. We added a line at the top of the cell to suppress a couple of warnings related to how we use `pd.to_datetime` here, but you need not worry about that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout\n",
    "\n",
    "# Run this cell to read the data into a DataFrame and do some initial formatting, no further action is needed.\n",
    "calls = pd.read_csv(\"data/Berkeley_PD_-_Calls_for_Service_2022.csv\")\n",
    "calls['EVENTTM'] = pd.to_datetime(calls['EVENTTM']).dt.strftime('%H:%M:%S %p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calls.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the fields include a case number, the offense type, the date and time of the offense, the \"CVLEGEND\" which appears to be related to the offense type, a \"CVDOW\" which has no apparent meaning, the date the record was added to the database, and the location spread across four fields. We can read more about each field from the City of Berkeley's [open dataset webpage](https://data.cityofberkeley.info/Public-Safety/Berkeley-PD-Calls-for-Service/k2nh-s5h5).\n",
    "\n",
    "Let's also check some basic information about this `DataFrame` using the `pandas.DataFrame.info` ([documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.info.html)) and `pandas.DataFrame.describe` methods ([documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# df.info() displays name and type of each column, and\n",
    "# number of non-null entries in each column\n",
    "calls.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the BLKADDR column only has 4476 non-null entries, while the other columns all have 4490 entries. This is because the `.info()` method only counts non-null entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "calls.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "explore-4",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Notice that the functions above reveal type information for the columns, as well as some basic statistics about the numerical columns found in the `DataFrame`. However, we still need more information about what each column represents. Let's explore the data further in Question 1.\n",
    "\n",
    "Before we go over the fields to deduce their meanings, the cell below will verify that all the events happened in Berkeley by grouping on the `City` and `State` columns. You should see that all of our data falls into one group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# .size() returns the number of rows in each DataFrameGroupBy object\n",
    "calls.groupby([\"City\", \"State\"]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "When we called `.head()` on the `DataFrame` `calls`, it seemed like `OFFENSE` and `CVLEGEND` both contained information about the type of event reported. What is the difference in meaning between the two columns? One way to probe this is to look at the `value_counts` for each `Series`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "calls['OFFENSE'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "calls['CVLEGEND'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "It seems like `OFFENSE` is more specific than `CVLEGEND`, e.g., \"LARCENY\" vs. \"THEFT FELONY (OVER $950)\". If you're unfamiliar with the term, \"larceny\" is a legal term for theft of personal property.\n",
    "\n",
    "To get a sense of how many sub-categories there are for each `OFFENSE`, we will set `calls_by_cvlegend_and_offense` equal to a multi-indexed `Series` where the data is first indexed on the `CVLEGEND` and then on the `OFFENSE`, and the data is equal to the number of offenses in the database that match the respective `CVLEGEND` and `OFFENSE`. As you can see, `calls_by_cvlegend_and_offense[\"LARCENY\", \"THEFT FROM PERSON\"]` returns `13` which means there are 13 instances of larceny with offense of type \"THEFT FROM PERSON\" in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calls_by_cvlegend_and_offense = calls.groupby([\"CVLEGEND\", \"OFFENSE\"]).size()\n",
    "calls_by_cvlegend_and_offense[\"LARCENY\", \"THEFT FROM PERSON\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 1\n",
    "\n",
    "In the cell below, set `answer1` equal to a `list` of strings corresponding to the possible values for `OFFENSE` when `CVLEGEND` is \"LARCENY\". You can type the answer manually, or you can create an expression that automatically extracts the names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "answer1 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "setup",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "# Part 3: Visualize the Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "part2",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### `Matplotlib` demo\n",
    "\n",
    "You've seen some `matplotlib` in this class already (in homework 1), but now we will explain how to work with the object-oriented plotting API mentioned in this [matplotlib.pyplot tutorial](https://matplotlib.org/tutorials/introductory/pyplot.html). In `matplotlib`, plotting occurs on a set of `Axes` that are associated with a `Figure`. An analogy is that on a blank canvas (`Figure`), you choose a location to plot (`Axes`) and then fill it in (plot).\n",
    "\n",
    "There are two approaches to labeling and manipulating figure contents, which we'll discuss below. Approach 1 is closest to the plotting paradigm of MATLAB, the namesake of `matplotlib`; Approach 2 is also common because many `matplotlib`-based packages (such as `seaborn`) explicitly return the current set of axes after plotting data. Both are essentially equivalent, and at the end of this class, you'll be comfortable with both. \n",
    "\n",
    "**Approach 1**: `matplotlib` will auto-plot onto the current set of `Axes` or (if none exists) create a new figure/set of default axes. You can plot data using methods from `plt`, which is shorthand for the `matplotlib.pyplot` package. Then subsequent `plt` calls all edit the same set of default-created axes.\n",
    "\n",
    "**Approach 2**:  \n",
    "After creating the initial plot, you can also use `plt.gca()` to explicitly get the current set of axes and then edit those specific axes using axes methods. Note the method naming is slightly different!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas` also offers basic functionality for plotting. For example, the `DataFrame` and `Series` classes both have a `plot` method, which uses `matplotlib` under the hood. For now, we'll focus on `matplotlib` itself so you get used to the syntax, but just know that convenient `pandas` plotting methods exist for your own future data science exploration.\n",
    "\n",
    "Below, we show both approaches by generating a horizontal bar plot to visually display the value counts for `CVLEGEND`. See the `barh` [documentation](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.barh.html?highlight=barh#matplotlib.pyplot.barh) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEMO CELL: assign demo to 1 or 2.\n",
    "demo = ...\n",
    "\n",
    "calls_cvlegend = calls['CVLEGEND'].value_counts()\n",
    "\n",
    "if demo == 1:\n",
    "    plt.barh(calls_cvlegend.index, calls_cvlegend) # Creates figure and axes\n",
    "    print(f\"Demo {demo}: Using plt methods to update plot\")\n",
    "    plt.ylabel(\"Crime Category\")               # Uses most recently plotted axes\n",
    "    plt.xlabel(\"Number of Calls\")\n",
    "    plt.title(\"Number of Calls by Crime Type\")\n",
    "elif demo == 2:\n",
    "    print(f\"Demo {demo}: Using axes methods to update plot\")\n",
    "    plt.barh(calls_cvlegend.index, calls_cvlegend) # Creates figure and axes\n",
    "    ax = plt.gca()\n",
    "    ax.set_ylabel(\"Crime Category\")\n",
    "    ax.set_xlabel(\"Number of Calls\")\n",
    "    ax.set_title(\"Axes methods: Number of Calls by Crime Type\")\n",
    "else:\n",
    "    print(\"Error: Please assign the demo variable to 1 or 2.\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "plot-demo6",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "\n",
    "### An Additional Note on Plotting in Jupyter Notebooks\n",
    "\n",
    "You may have noticed that some of our plotting code cells end with a semicolon `;` or `plt.show()`. The former prevents any extra output from the last line of the cell; the latter explicitly returns (and outputs) the figure. Try adding this to your own code in the following questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 2\n",
    "\n",
    "Now it is your turn to make a plot using `matplotlib`. Let's start by transforming the data so that it is easier to work with.\n",
    "\n",
    "The `CVDOW` field isn't named helpfully, and it is hard to see the meaning from the data alone. According to the website [linked](https://data.cityofberkeley.info/Public-Safety/Berkeley-PD-Calls-for-Service/k2nh-s5h5) at the top of this notebook, `CVDOW` is actually indicating the day that events happened. 0->Sunday, 1->Monday ... 6->Saturday. \n",
    "\n",
    "### Question 2a\n",
    "\n",
    "Add a new column `Day` to `calls` that has the string weekday (e.g., \"Sunday\") for the corresponding value in CVDOW. For example, if the first 3 values of `CVDOW` are `[3, 6, 0]`, then the first 3 values of the `Day` column should be `[\"Wednesday\", \"Saturday\", \"Sunday\"]`.\n",
    "\n",
    "**Hint:** Try using the [Series.map](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.map.html) function on `calls[\"CVDOW\"]`. Can you assign this to the new column `calls[\"Day\"]`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3a-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "days = [\"Sunday\", \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\"]\n",
    "day_indices = range(7)\n",
    "indices_to_days_dict = dict(zip(day_indices, days)) # Should look like {0:\"Sunday\", 1:\"Monday\", ..., 6:\"Saturday\"}\n",
    "\n",
    "calls[\"Day\"] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "### Question 2b\n",
    "\n",
    "Now let's look at the `EVENTTM` column which indicates the time for events. Since it contains hour and minute information, let's extract the hour info and create a new column named `Hour` in the `calls` `DataFrame`. **You should save the hour as an `int`**. The format of the `'EVENTTM'` column and some of the associated reasoning about the answer in the lab walkthrough is slightly different. However, the answer shown in the walkthrough is still applicable to the question below. \n",
    "\n",
    "**Hint:** Your code should only require one line. <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "calls[\"Hour\"] = ...\n",
    "calls[\"Hour\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "### Question 2c\n",
    "\n",
    "Using `matplotlib`, construct a line plot with the count of the number of calls (entries in the table) for each hour of the day  **ordered by the time** (e.g., `12:00 AM`, `1:00 AM`, ...). Be sure that your axes are labeled and that your plot is titled. The solution shown in the lab walkthrough is not the only way to answer this question, an alternative approach could involve using `.sort_index()`.\n",
    "\n",
    "**Hint 1**: Check out the `plt.plot` method in the `matplotlib` [tutorial](https://matplotlib.org/stable/tutorials/introductory/pyplot.html#intro-to-pyplot), as well as our demo above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "# Leave this for grading purposes.\n",
    "ax_3d = plt.gca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better understand the time of day a report occurs, we could **stratify the analysis by the day of the week.** To do this we will use **violin plots** (a variation of a **box plot**).\n",
    "\n",
    "A violin plot shows an estimated distribution of quantitative data (e.g., distribution of calls by hour) over a categorical variable (day of the week). More calls occur in hours corresponding to the fatter part of each violin; the median hour of all calls in a particular day is marked by the white dot in the corresponding violin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to to generate the plot, no further action is needed\n",
    "\n",
    "import seaborn as sns\n",
    "ax = sns.violinplot(data=calls.sort_values(\"CVDOW\"),\n",
    "                    x=\"Day\", y=\"Hour\",\n",
    "                    saturation=0.5, palette=\"Set2\")\n",
    "ax.set_title(\"Stratified Analysis of Phone Calls by Day\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "### Question 2d\n",
    "\n",
    "Based on your line plot and our violin plot above, what observations can you make about the patterns of calls? Here are some dimensions to consider:\n",
    "* Are there more calls in the day or at night?\n",
    "* What are the most and least popular times?\n",
    "* Do call patterns vary by day of the week?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "# Part 4: Data Faithfulness vs. Reality\n",
    "<br>\n",
    "\n",
    "## Question 3\n",
    "In this last part of the lab, let's extract the GPS coordinates (latitude, longitude) from the `Block_Location` of each record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example block location entry.\n",
    "calls.loc[4, 'Block_Location']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 3a: Regular Expressions\n",
    "\n",
    "Use regular expressions to create a new `DataFrame` `calls_lat_lon` that has two columns titled `Lat` and `Lon`, containing the respective latitude and longitude of each record in `calls`. You should use the `Block_Location` column to extract the latitude and longitude coordinates.\n",
    "\n",
    "**Hint**: Check out the `Series.str.extract` [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.extract.html?highlight=extract#pandas.Series.str.extract)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "calls_lat_lon = ...\n",
    "\n",
    "\n",
    "calls_lat_lon.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Question 3b: Join Tables\n",
    "\n",
    "Let's include the GPS data into our `calls` data. In the below cell, use `calls_lat_lon` to add two new columns called `Lat` and `Lon` to `calls`.\n",
    "\n",
    "**Hint 1**: Note that the order of records in `calls` and `calls_lat_lon` are the same. \n",
    "\n",
    "**Hint 2**: Another way to achieve our goal could be using `pd.merge`, look through the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html) to see how we can merge using the `left_index` and `right_index` arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "calls.sample(5)      # random rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "### Question 3c: Check for Invalid Values\n",
    "\n",
    "It seems like every record has valid GPS coordinates. That is, there are no `NaN` values in either column as we can verify below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to obtain fraction of valid lat/lon entries, no further action is needed.\n",
    "(~calls[[\"Lat\", \"Lon\"]].isna()).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, a closer examination of the data reveals something else. Here's the first few records of `calls` again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "calls.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "There is another field that tells us whether we have a valid `Block_Location` entry per record - i.e., with GPS coordinates (latitude, longitude) that match the listed block location. What is it?\n",
    "\n",
    "In the below cell, use the field you found to create a new `DataFrame`, `invalid_block_loc`, that contains only the rows of `calls` that have invalid `Block_Location`. Your new `DataFrame` should have all the same columns of `calls`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "invalid_block_loc = ...\n",
    "invalid_block_loc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "### Question 3d: Patterns in Invalid Values\n",
    "\n",
    "Now let's explore if there is a pattern to which types of records have invalid block locations.\n",
    "\n",
    "We've implemented the plotting code for you below, but read through it and verify you understand what we're doing (we've thrown in a bonus `plt.subplots()` call, documentation [here](https://matplotlib.org/stable/gallery/subplots_axes_and_figures/subplots_demo.html#stacking-subplots-in-one-direction))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to generate the plot, no further action is needed\n",
    "missing_by_time = (pd.to_datetime(invalid_block_loc['EVENTDT'], format='%m/%d/%Y %I:%M:%S %p')\n",
    "                   .value_counts()\n",
    "                   .sort_index()\n",
    "                  )\n",
    "missing_by_crime = (invalid_block_loc['CVLEGEND']\n",
    "                    .value_counts() \n",
    "                    / calls['CVLEGEND'].value_counts()\n",
    "                   ).dropna().sort_values(ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(2)\n",
    "ax[0].bar(missing_by_time.index, missing_by_time)\n",
    "ax[0].set_ylabel(\"Calls with Invalid Data\")\n",
    "ax[1].barh(missing_by_crime.index, missing_by_crime)\n",
    "ax[1].set_xlabel(\"Fraction of Invalid Data per Event Type\")\n",
    "fig.suptitle(\"Characteristics of Invalid Lat/Lon Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "\n",
    "Based on the plots above, are there any patterns among entries that are invalid latitude/longitude data? The dataset information [linked](https://data.cityofberkeley.info/Public-Safety/Berkeley-PD-Calls-for-Service/k2nh-s5h5) at the top of this notebook may also give more context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "### Question 3e: Explore\n",
    "\n",
    "The below cell plots a map of phone calls by GPS coordinates (latitude, longitude); we drop invalid location data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to generate the interactive plot, no further code is needed.\n",
    "import folium\n",
    "import folium.plugins\n",
    "\n",
    "SF_COORDINATES = (37.87, -122.28)\n",
    "sf_map = folium.Map(location=SF_COORDINATES, zoom_start=13)\n",
    "locs = calls.drop(invalid_block_loc.index)[['Lat', 'Lon']].astype('float').values\n",
    "heatmap = folium.plugins.HeatMap(locs.tolist(), radius=10)\n",
    "sf_map.add_child(heatmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Based on the above map, what could be some **drawbacks** of using the location fields in this dataset to draw conclusions about crime in Berkeley? This is an open-ended question. Here are some sub-questions to consider:\n",
    "* Is campus really the safest place to be?\n",
    "* Why are all the calls located at street intersections, outdoors, and not within buildings?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Congratulations! You have finished Lab 3!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False, run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1": {
     "name": "q1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(answer1, list)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> all([isinstance(elt, str) for elt in answer1])\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> len(answer1) == 3\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> all([elt in calls['OFFENSE'].values for elt in answer1])\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> set([a.strip().upper() for a in answer1]) == set(['THEFT FELONY (OVER $950)', 'THEFT FROM PERSON', 'THEFT MISD. (UNDER $950)'])\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2a": {
     "name": "q2a",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> set(calls[\"Day\"]) == {'Friday', 'Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday', 'Wednesday'}\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> # 2021 \n>>> # list(calls[\"Day\"][:5]) == ['Thursday', 'Thursday', 'Monday', 'Saturday', 'Monday']\n>>> # 2022\n>>> list(calls[\"Day\"][:5])  == ['Wednesday', 'Thursday', 'Wednesday', 'Friday', 'Wednesday']\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2b": {
     "name": "q2b",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(calls.loc[72, 'Hour'], (int, np.integer))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> calls['Hour'][72] == 18\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2c": {
     "name": "q2c",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> hours = list(range(24))\n>>> xy_data = ax_3d.lines[0].get_xydata()\n>>> expected_xy_data = np.vstack((hours, calls[\"Hour\"].value_counts()[hours].to_numpy())).T\n>>> np.allclose(xy_data, expected_xy_data)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> plt.close('all')\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3a": {
     "name": "q3a",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> calls_lat_lon.shape\n(4490, 2)",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> set(calls_lat_lon.columns) == {\"Lat\", \"Lon\"}\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3b": {
     "name": "q3b",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> ('Lat' in calls.columns) and ('Lon' in calls.columns)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> str(calls.loc[1137, \"Lat\"]) == '37.8801'\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> str(calls.loc[689][\"Lon\"]) == '-122.26857'\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3c": {
     "name": "q3c",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> invalid_block_loc.shape\n(14, 15)",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> invalid_block_loc[\"BLKADDR\"].isna().sum() == len(invalid_block_loc)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
