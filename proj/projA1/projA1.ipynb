{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"projA1.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e0f9b2de18190d9d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Project A1: Exploring Cook County Housing\n",
    "\n",
    "## Due Date: Saturday, October 21st 11:59 PM PDT\n",
    "You must submit this assignment to Gradescope by the on-time deadline, Saturday, October at 11:59 PM. Please read the syllabus for the grace period policy. No late submissions beyond the grace period will be accepted. While course staff is happy to help you if you encounter difficulties with submission, we may not be able to respond to last-minute requests for assistance (TAs need to sleep, after all!). **We strongly encourage you to plan to submit your work to Gradescope several hours before the stated deadline.** This way, you will have ample time to reach out to staff for submission support. \n",
    "\n",
    "### Collaboration Policy\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with others about the homework, we ask that you **write your solutions individually**. If you do discuss the assignments with others please **include their names** in the collaborators cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Collaborators:** *list names here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This project explores what can be learned from an extensive housing dataset that is embedded in a dense social context in Cook County, Illinois.\n",
    "\n",
    "In project A1 (this assignment), we will guide you through some basic Exploratory Data Analysis (EDA) to understand the structure of the data. Next, you will be adding a few new features to the dataset, while cleaning the data as well in the process.\n",
    "\n",
    "In project A2 (the following assignment), you will specify and fit a linear model for the purpose of prediction. Finally, we will analyze the error of the model and brainstorm ways to improve the model's performance.\n",
    "\n",
    "\n",
    "## Grading\n",
    "Grading is broken down into autograded answers and free response. \n",
    "\n",
    "For autograded answers, the results of your code are compared to provided and/or hidden tests.\n",
    "\n",
    "For free response, readers will evaluate how well you answered the question and/or fulfilled the requirements of the question.\n",
    "\n",
    "Question | Manual | Points\n",
    "----|----|----\n",
    "1a | Yes | 1\n",
    "1b | Yes | 1\n",
    "1c | Yes | 1\n",
    "1d | Yes | 1\n",
    "2a | Yes | 1\n",
    "2b | No | 1\n",
    "3a | No | 1\n",
    "3b | No | 1\n",
    "3c | Yes | 1\n",
    "4 | No | 2\n",
    "5a | No | 1\n",
    "5b | No | 2\n",
    "5c | Yes | 2\n",
    "6a | No | 1\n",
    "6b | No | 2\n",
    "6c | No | 2\n",
    "6d | No | 1\n",
    "7a | No | 1\n",
    "7b | No | 2\n",
    "Total | 7 | 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-62cfd21463535cac",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Plot settings\n",
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "# The Data\n",
    "\n",
    "The dataset consists of over 500,000 records from Cook County, Illinois, the county where Chicago is located. The dataset has 61 features in total; the 62nd is `Sale Price`, which you will predict with linear regression in the next part of this project. An explanation of each variable can be found in the included `codebook.txt` file (you can optionally open this by first clicking the `data` folder, then clicking `codebook.txt` file in the navigation pane). Some of the columns have been filtered out to ensure this assignment doesn't become overly long when dealing with data cleaning and formatting.\n",
    "\n",
    "The data are split into training and test sets with 204,792 and 68,264 observations, respectively, but we will only be working on the training set for this part of the project.\n",
    "\n",
    "Let's first extract the data from the `cook_county_data.zip`. Notice we didn't leave the `csv` files directly in the directory because they take up too much space without some prior compression. Just run the cells below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('data/cook_county_data.zip') as item:\n",
    "    item.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e8fea30adc9d489b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(\"cook_county_train.csv\", index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9d6d509b6e854e10",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "As a good sanity check, we should at least verify that the data shape matches the description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c841a2de55691502",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 204,792 observations and 62 features in training data\n",
    "assert training_data.shape == (204792, 62)\n",
    "# Sale Price is provided in the training data\n",
    "assert 'Sale Price' in training_data.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ce9acc2f62c96e59",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "The next order of business is getting a feel for the variables in our data.  A more detailed description of each variable is included in `codebook.txt` (in the same directory as this notebook).  **You should take some time to familiarize yourself with the codebook before moving forward.**\n",
    "\n",
    "Let's take a quick look at all the current columns in our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4e60a7a0cda5eecf",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "training_data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data['Description'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "# Part 1: Contextualizing the Data\n",
    "\n",
    "Let's try to understand the background of our dataset before diving into a full-scale analysis. \n",
    "\n",
    "**Note**: We will explore this dataset and its social context in greater detail in Lecture 15: Case Study (HCE). For now, we ask you to familiarize yourself with the overall structure of the dataset and the information it contains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 1a\n",
    "\n",
    "Based on the columns in this dataset and the values that they take, what do you think each row represents? That is, what is the granularity of this dataset? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br><br>\n",
    "\n",
    "---\n",
    "## Question 1b\n",
    "Why do you think this data was collected? For what purposes? By whom?\n",
    "\n",
    "This question calls for your speculation and is looking for thoughtfulness, not correctness. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br><br>\n",
    "\n",
    "---\n",
    "## Question 1c\n",
    "\n",
    "Craft at least two questions about housing in Cook County that can be answered with this dataset and provide the type of analytical tool you would use to answer it (e.g. \"I would create a ___ plot of ___ and ___\" or \"I would calculate the ___ [summary statistic] for ___ and ____\"). Be sure to reference the columns that you would use and any additional datasets you would need to answer that question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br><br>\n",
    "\n",
    "---\n",
    "## Question 1d\n",
    "\n",
    "Suppose now, in addition to the information already contained in the dataset, you also have access to several new columns containing demographic data about the owner, including race/ethnicity, gender, age, annual income, and occupation. Provide one new question about housing in Cook County that can be answered using at least one column of demographic data and at least one column of existing data and provide the type of analytical tool you would use to answer it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ba0f6926b0dafefb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br/><br/>\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "# Part 2: Exploratory Data Analysis\n",
    "\n",
    "This dataset was collected by the [Cook County Assessor's Office](https://datacatalog.cookcountyil.gov/Property-Taxation/Archive-Cook-County-Assessor-s-Residential-Sales-D/5pge-nu6u) in order to build a model to predict the monetary value of a home. You can read more about data collection in the CCAO’s [Residential Data Integrity Preliminary Report](https://gitlab.com/ccao-data-science---modeling/ccao_sf_cama_dev/-/blob/master/documentation/Preliminary%20Report%20on%20Data%20Integrity%20June%207,%202019.pdf). In Project A2, you will be building a linear regression model that predicts sales prices using training data, but it's important to first understand how the structure of the data informs such a model. In this section, we will make a series of exploratory visualizations and feature engineering in preparation for that prediction task.\n",
    "\n",
    "Note that we will perform EDA on the **training data**.\n",
    "\n",
    "### Sale Price\n",
    "We begin by examining the distribution of our target variable `Sale Price`. We have provided the following helper method `plot_distribution` that you can use to visualize the distribution of the `Sale Price` using both the histogram and the box plot at the same time. Run the following 2 cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-15d483a695655cea",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_distribution(data, label):\n",
    "    fig, axs = plt.subplots(nrows=2)\n",
    "\n",
    "    sns.distplot(\n",
    "        data[label], \n",
    "        ax=axs[0]\n",
    "    )\n",
    "    sns.boxplot(\n",
    "        x=data[label],\n",
    "        width=0.3, \n",
    "        ax=axs[1],\n",
    "        showfliers=False,\n",
    "    )\n",
    "\n",
    "    # Align axes\n",
    "    spacer = np.max(data[label]) * 0.05\n",
    "    xmin = np.min(data[label]) - spacer\n",
    "    xmax = np.max(data[label]) + spacer\n",
    "    axs[0].set_xlim((xmin, xmax))\n",
    "    axs[1].set_xlim((xmin, xmax))\n",
    "\n",
    "    # Remove some axis text\n",
    "    axs[0].xaxis.set_visible(False)\n",
    "    axs[0].yaxis.set_visible(False)\n",
    "    axs[1].yaxis.set_visible(False)\n",
    "\n",
    "    # Put the two plots together\n",
    "    plt.subplots_adjust(hspace=0)\n",
    "    fig.suptitle(\"Distribution of \" + label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(training_data, label='Sale Price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the same time, we also take a look at some descriptive statistics of this variable. Run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data['Sale Price'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br><br>\n",
    "\n",
    "---\n",
    "## Question 2a\n",
    "\n",
    "Using the plots above and the descriptive statistics from `training_data['Sale Price'].describe()` in the cells above, identify one issue with the visualization above and briefly describe one way to overcome it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional cell for scratch work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br><br>\n",
    "\n",
    "---\n",
    "## Question 2b\n",
    "\n",
    "To zoom in on the visualization of most households, we will focus only on a subset of `Sale Price` for this assignment. In addition, it may be a good idea to apply log transformation to `Sale Price`. In the cell below, reassign `training_data` to a new dataframe that is the same as the original one **except with the following changes**:\n",
    "\n",
    "- `training_data` should contain only households whose price is at least $500.\n",
    "- `training_data` should contain a new `Log Sale Price` column that contains the log-transformed sale prices.\n",
    "\n",
    "**You should NOT remove the original column `Sale Price` as it will be helpful for later questions.** If you accidentally remove it, just restart your kernel and run the cells again.\n",
    "\n",
    "**Note**: This also implies from now on, our target variable in the model will be the log-transformed sale prices from the column `Log Sale Price`. \n",
    "\n",
    "*To ensure that any error from this part does not propagate to later questions, there will be no hidden tests for this question.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a new distribution plot on the log-transformed sale price. As a sanity check, you should see that the distribution for the Log Scale Price is much more uniform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(training_data, label='Log Sale Price');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br><br>\n",
    "\n",
    "---\n",
    "## Question 3a\n",
    "\n",
    "\n",
    "Is the following statement correct? Assign your answer to `q3statement`.\n",
    "\n",
    "     \"At least 25% of the properties in the training set sold for more than $200,000.00.\"\n",
    "\n",
    "**Note:** The provided test for this question does not confirm that you have answered correctly; only that you have assigned each variable to `True` or `False`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1-answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This should be set to True or False\n",
    "q3statement = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br><br>\n",
    "\n",
    "---\n",
    "## Question 3b\n",
    "\n",
    "Next, we want to explore if there is any correlation between `Log Sale Price` and the total area occupied by the property. The `codebook.txt` file tells us the column `Building Square Feet` should do the trick -- it measures \"(from the exterior) the total area, in square feet, occupied by the building\".\n",
    "\n",
    "Let's also apply a log transformation to the `Building Square Feet` column.\n",
    "\n",
    "In the following cell, create a new column `Log Building Square Feet` in our `training_data` that contains the log-transformed area occupied by each property. \n",
    "\n",
    "**You should NOT remove the original `Building Square Feet` column this time, as it will be used for later questions**. If you accidentally remove it, just restart your kernel and run the cells again.\n",
    "\n",
    "*To ensure that any errors from this part do not propagate to later questions, there will be no hidden tests for this question.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_data['Log Building Square Feet'] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br><br>\n",
    "\n",
    "---\n",
    "## Question 3c\n",
    "\n",
    "In the visualization below, we created a `jointplot` with `Log Building Square Feet` on the x-axis, and `Log Sale Price` on the y-axis. In addition, we fit a simple linear regression line through the bivariate scatter plot in the middle.\n",
    "\n",
    "Based on the following plot, would `Log Building Square Feet` make a good candidate as one of the features for our model? Why or why not?\n",
    "\n",
    "**Hint:** To help answer this question, ask yourself: what kind of relationship does a “good” feature share with the target variable we aim to predict?\n",
    "\n",
    "![Joint Plot](images/q2p3_jointplot.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>\n",
    "\n",
    "---\n",
    "## Question 4\n",
    "\n",
    "Continuing from the previous part, as you explore the dataset, you might still run into more outliers that prevent you from creating a clear visualization or capturing the trend of the majority of the houses. \n",
    "\n",
    "For this assignment, we will work to remove these outliers from the data as we run into them. Write a function `remove_outliers` that removes outliers from the dataset based off a threshold value of a variable. For example, `remove_outliers(training_data, 'Building Square Feet', lower=500, upper=8000)` should return a copy of `data` with only observations that satisfy `Building Square Feet` less than or equal to 8000 (inclusive) and `Building Square Feet` greater than 500 (exclusive).\n",
    "\n",
    "**Note:** The provided tests simply check that the `remove_outliers` function you defined does not mutate the input data inplace. However, the provided tests do not check that you have implemented `remove_outliers` correctly so that it works with any data, variable, lower, and upper bound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9186ec2ca053d0aa",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_outliers(data, variable, lower=-np.inf, upper=np.inf):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      data (DataFrame): the table to be filtered\n",
    "      variable (string): the column with numerical outliers\n",
    "      lower (numeric): observations with values lower than or equal to this will be removed\n",
    "      upper (numeric): observations with values higher than this will be removed\n",
    "    \n",
    "    Output:\n",
    "      a DataFrame with outliers removed\n",
    "      \n",
    "    Note: This function should not change mutate the contents of data.\n",
    "    \"\"\"  \n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br/><br/>\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "# Part 3: Feature Engineering\n",
    "\n",
    "In this section, we will walk you through a few feature engineering techniques. \n",
    "\n",
    "### Bedrooms\n",
    "\n",
    "Let's start simple by extracting the total number of bedrooms as our first feature for the model. You may notice that the `Bedrooms` column doesn't actually exist in the original `DataFrame`! Instead, it is part of the `Description` column.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "---\n",
    "## Question 5a\n",
    "\n",
    "Let's take a closer look at the `Description` column first. Compare the description across a few rows together at the same time. For the following list of variables, how many of them can be extracted from the `Description` column? Assign your answer to a list of integers corresponding to the statements that you think are true (ie. `[1, 2, 3]`).\n",
    "\n",
    "1. The date the property was sold on.\n",
    "2. The number of stories the property contains.\n",
    "3. The previous owner of the property.\n",
    "4. The address of the property.\n",
    "5. The number of garages the property has.\n",
    "6. The total number of rooms inside the property.\n",
    "7. The total number of bedrooms inside the property.\n",
    "8. The total number of bathrooms inside the property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# optional cell for scratch work "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q5a = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional cell for scratch work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br><br>\n",
    "\n",
    "---\n",
    "## Question 5b\n",
    "\n",
    "Write a function `add_total_bedrooms(data)` that returns a copy of `data` with an additional column called `Bedrooms` that contains the total number of bedrooms (**as integers**) for each house. Treat missing values as zeros, if necessary. Remember that you can make use of vectorized code here; you shouldn't need any `for` statements. \n",
    "\n",
    "**Hint**: You should consider inspecting the `Description` column to figure out if there is any general structure within the text. Once you have noticed a certain pattern, you are set with the power of Regex!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_total_bedrooms(data):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      data (DataFrame): a DataFrame containing at least the Description column.\n",
    "\n",
    "    Output:\n",
    "      a Dataframe with a new column \"Bedrooms\" containing ints.\n",
    "\n",
    "    \"\"\"\n",
    "    with_rooms = data.copy()\n",
    "    ...\n",
    "    return with_rooms\n",
    "\n",
    "training_data = add_total_bedrooms(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br><br>\n",
    "\n",
    "---\n",
    "## Question 5c\n",
    "\n",
    "Create a visualization that clearly and succinctly shows if there exists an association between  `Bedrooms` and `Log Sale Price`. A good visualization should satisfy the following requirements:\n",
    "- It should avoid overplotting.\n",
    "- It should have clearly labeled axes and a succinct title.\n",
    "- It should convey the strength of the correlation between `Sale Price` and the number of rooms: in other words, you should be able to look at the plot and describe the general relationship between `Log Sale Price` and `Bedrooms`\n",
    "\n",
    "**Hint**: A direct scatter plot of the `Sale Price` against the number of rooms for all of the households in our training data might risk overplotting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "Now, let's take a look at the relationship between neighborhood and sale prices of the houses in our dataset.\n",
    "Notice that currently we don't have the actual names for the neighborhoods. Instead we will use a similar column `Neighborhood Code` (which is a numerical encoding of the actual neighborhoods by the Assessment office)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br><br>\n",
    "\n",
    "---\n",
    "## Question 6a\n",
    "\n",
    "Before creating any visualization, let's quickly inspect how many different neighborhoods we are dealing with.\n",
    "\n",
    "Assign the variable `num_neighborhoods` with the total number of unique neighborhoods in `training_data`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_neighborhoods = ...\n",
    "num_neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "---\n",
    "## Question 6b\n",
    "\n",
    "If we try directly plotting the distribution of `Log Sale Price` for all of the households in each neighborhood using the `plot_categorical` function from the next cell, we would get the following visualization.\n",
    "\n",
    "\n",
    "![overplot](images/q5p2_catplot.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_categorical(neighborhoods):\n",
    "    fig, axs = plt.subplots(nrows=2)\n",
    "\n",
    "    sns.boxplot(\n",
    "        x='Neighborhood Code',\n",
    "        y='Log Sale Price',\n",
    "        data=neighborhoods,\n",
    "        ax=axs[0],\n",
    "    )\n",
    "\n",
    "    sns.countplot(\n",
    "        x='Neighborhood Code',\n",
    "        data=neighborhoods,\n",
    "        ax=axs[1],\n",
    "    )\n",
    "\n",
    "    # Draw median price\n",
    "    axs[0].axhline(\n",
    "        y=training_data['Log Sale Price'].median(), \n",
    "        color='red',\n",
    "        linestyle='dotted'\n",
    "    )\n",
    "\n",
    "    # Label the bars with counts\n",
    "    for patch in axs[1].patches:\n",
    "        x = patch.get_bbox().get_points()[:, 0]\n",
    "        y = patch.get_bbox().get_points()[1, 1]\n",
    "        axs[1].annotate(f'{int(y)}', (x.mean(), y), ha='center', va='bottom')\n",
    "\n",
    "    # Format x-axes\n",
    "    axs[1].set_xticklabels(axs[1].xaxis.get_majorticklabels(), rotation=90)\n",
    "    axs[0].xaxis.set_visible(False)\n",
    "\n",
    "    # Narrow the gap between the plots\n",
    "    plt.subplots_adjust(hspace=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Oh no, looks like we have run into the problem of overplotting again! \n",
    "\n",
    "You might have noticed that the graph is overplotted because **there are actually quite a few neighborhoods in our dataset**! For the clarity of our visualization, we will have to zoom in again on a few of them. The reason for this is our visualization will become quite cluttered with a super dense x-axis.\n",
    "\n",
    "Assign the variable `in_top_20_neighborhoods` to a copy of `training_data` that has been filtered to only contain rows corresponding to properties that are in one of the top 20 most populous neighborhoods. We define the “top 20 neighborhoods” as being the 20 neighborhood codes that have the greatest number of properties within them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "top_20_neighborhood_codes = ...\n",
    "in_top_20_neighborhoods = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create another of the distribution of sale price within in each neighborhood again, but this time with a narrower focus!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_categorical(neighborhoods=in_top_20_neighborhoods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br><br>\n",
    "\n",
    "---\n",
    "## Question 6c\n",
    "\n",
    "From the plot above, we can see that there is much less data available for some neighborhoods. For example, Neighborhood 71 has only around 27% of the number of datapoints as Neighborhood 30.\n",
    "\n",
    "One way we can deal with the lack of data from some neighborhoods is to create a new feature that bins neighborhoods together. We’ll categorize our neighborhoods in a crude way. In Question 6c, we’ll compute how “expensive” each neighborhood is by aggregating the `Log Sale Price`s for all properties in a particular neighborhood using a `metric`, such as the median. We’ll use this `metric` to find the top `n` most expensive neighborhoods. Then, in Question 6d, we’ll label these “expensive neighborhoods” and leave all other neighborhoods unmarked.\n",
    "\n",
    "Fill in `find_expensive_neighborhoods` to return a **list** of the neighborhood codes of the **top `n`** most expensive neighborhoods as measured by our choice of aggregating function, `metric`.\n",
    "\n",
    "For example, calling `find_expensive_neighborhoods(training_data, n=3, metric=np.median)` should return the 3 neighborhood codes with the highest median `Log Sale Price` computed across all properties in those neighborhood codes. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_expensive_neighborhoods(data, n=3, metric=np.median):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      data (DataFrame): should contain at least a int-valued 'Neighborhood Code'\n",
    "        and a numeric 'Log Sale Price' column\n",
    "      n (int): the number of top values desired\n",
    "      metric (function): function used for aggregating the data in each neighborhood.\n",
    "        for example, np.median for median prices\n",
    "    \n",
    "    Output:\n",
    "      a list of the the neighborhood codes of the top n highest-priced neighborhoods \n",
    "      as measured by the metric function\n",
    "    \"\"\"\n",
    "    neighborhoods = ...\n",
    "    \n",
    "    # This makes sure the final list contains the generic int type used in Python3, not specific ones used in numpy.\n",
    "    return [int(code) for code in neighborhoods]\n",
    "\n",
    "expensive_neighborhoods = find_expensive_neighborhoods(training_data, 3, np.median)\n",
    "expensive_neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br><br>\n",
    "\n",
    "---\n",
    "## Question 6d\n",
    "\n",
    "We now have a list of neighborhoods we've deemed as higher-priced than others.  Let's use that information to write an additional function `add_expensive_neighborhood` that takes in a `DataFrame` of housing data (`data`) and a list of neighborhood codes considered to be expensive (`expensive_neighborhoods`). You can think of `expensive_neighborhoods` as being the output of the function `find_expensive_neighborhoods` from Question 6c. \n",
    "\n",
    "Using these inputs, `add_expensive_neighborhood` should add a column to `data` named `in_expensive_neighborhood` that takes on the **integer** value of 1 if a property is part of a neighborhood in `expensive_neighborhoods` and the integer value of 0 if it is not. This type of variable is known as an **indicator variable**.\n",
    "\n",
    "**Hint:** [`pd.Series.astype`](https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.Series.astype.html) may be useful for converting `True`/`False` values to integers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_in_expensive_neighborhood(data, expensive_neighborhoods):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      data (DataFrame): a DataFrame containing a 'Neighborhood Code' column with values\n",
    "        found in the codebook\n",
    "      neighborhoods (list of strings): strings should be the names of neighborhoods\n",
    "        pre-identified as expensive\n",
    "    Output:\n",
    "      DataFrame identical to the input with the addition of a binary\n",
    "      in_expensive_neighborhood column\n",
    "    \"\"\"\n",
    "    data['in_expensive_neighborhood'] = ...\n",
    "    return data\n",
    "\n",
    "expensive_neighborhoods = find_expensive_neighborhoods(training_data, 3, np.median)\n",
    "training_data = add_in_expensive_neighborhood(training_data, expensive_neighborhoods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following question, we will take a closer look at the `Roof Material` feature of the dataset and examine how we can incorporate categorical features into our linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br><br>\n",
    "\n",
    "---\n",
    "## Question 7a\n",
    "\n",
    "If we look at `codebook.txt` carefully, we can see that the Assessor's Office uses the following mapping for the numerical values in the `Roof Material` column.\n",
    "```\n",
    "Roof Material (Nominal): \n",
    "\n",
    "       1    Shingle/Asphalt\n",
    "       2    Tar & Gravel\n",
    "       3    Slate\n",
    "       4    Shake\n",
    "       5    Tile\n",
    "       6    Other\n",
    "```\n",
    "\n",
    "Write a function `substitute_roof_material` that replaces each numerical value in `Roof Material` with their corresponding roof material. Your function should return a new `DataFrame`, not modify the existing `DataFrame`.\n",
    "\n",
    "**Hint**: the `DataFrame.replace` ([documentation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.replace.html)) method may be useful here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def substitute_roof_material(data):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      data (DataFrame): a DataFrame containing a 'Roof Material' column.  Its values\n",
    "                         should be limited to those found in the codebook\n",
    "    Output:\n",
    "      DataFrame identical to the input except with a refactored 'Roof Material' column\n",
    "    \"\"\"\n",
    "    ...\n",
    "    return data\n",
    "    \n",
    "training_data_mapped = substitute_roof_material(training_data)\n",
    "training_data_mapped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br><br>\n",
    "\n",
    "---\n",
    "## Question 7b\n",
    "\n",
    "#### An Important Note on One Hot Encoding \n",
    "\n",
    "Unfortunately, simply replacing the integers with the appropriate strings isn’t sufficient for using `Roof Material` in our model.  Since `Roof Material` is a categorical variable, we will have to one-hot-encode the data. For more information on why we want to use one-hot-encoding, refer to this [link](https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/).\n",
    "\n",
    "Complete the following function `ohe_roof_material` that returns a `DataFrame` with the new column one-hot-encoded on the roof material of the household. These new columns should have the form `Roof Material_MATERIAL`. Your function should return a new `DataFrame` and **should not modify the existing `DataFrame`**.\n",
    "\n",
    "You should use Scikit-learn’s `OneHotEncoder` to perform the one-hot-encoding. `OneHotEncoder` will automatically generate column names of the form `Roof Material_MATERIAL`. Refer back to the video walkthrough for Question 1 of Lab 7 for an example of its use. Note that unlike in the lab example, in this problem we only wish to construct the one-hot-encoding columns **without removing any columns**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def ohe_roof_material(data):\n",
    "    \"\"\"\n",
    "    One-hot-encodes roof material. New columns are of the form \"Roof Material_MATERIAL\".\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "training_data_ohe = ohe_roof_material(training_data_mapped)\n",
    "# This line of code will display only the one-hot-encoded columns in training_data_ohe that \n",
    "# have names that begin with “Roof Material_\" \n",
    "training_data_ohe.filter(regex='^Roof Material_').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Sonia congratulates you for finishing Project A1!\n",
    "\n",
    "<div align=\"middle\">\n",
    "    <table style=\"width:100%\">\n",
    "      <tr align=\"center\">\n",
    "        <td><img src=\"images/sonia_1.jpeg\" align=\"middle\" width=\"250vw\" />\n",
    "        </td>\n",
    "        <td><img src=\"images/sonia_2.jpeg\" align=\"middle\" width=\"250vw\" />\n",
    "        </td>\n",
    "          <td><img src=\"images/sonia_3.jpeg\" align=\"middle\" width=\"250vw\" />\n",
    "        </td>\n",
    "      </tr>\n",
    "    </table>\n",
    "  </div>\n",
    "\n",
    "What's next? In Project A2, you will focus on building a linear regression model to predict house prices. You will be well-prepared to build such a model: you have considered what is in this dataset, what it can be used for, and engineered some features that should be useful for prediction. However, before we proceed in creating a house-pricing model for Cook County, we will need to consider some challenging social implications that this model may carry. We’ll explore these in greater detail in Lecture 15.\n",
    "\n",
    "\n",
    "Below, you will see two cells. Running the first cell will automatically generate a PDF of all questions that need to be manually graded, and running the second cell will automatically generate a zip with your autograded answers. **You are responsible for both the coding portion (the zip from Project A1) and the written portion (the PDF with from Project A1) to their respective Gradescope portals.** The coding proportion should be submitted to Project A1 Coding as a single zip file, and the written portion should be submitted to Project A1 Written as a single pdf file. When submitting the written portion, please ensure you select pages appropriately. \n",
    "\n",
    "If there are issues with automatically generating the PDF in the first cell, you can try downloading the notebook as a PDF by clicking on `File -> Save and Export Notebook As... -> PDF`. If that doesn't work either, you can manually take screenshots of your answers to the manually graded questions and submit those. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**\n",
    "\n",
    "After you have run the cell below and generated the zip file, you can open the PDF <a href='projA1.pdf' download>here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q2b": {
     "name": "q2b",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> 'Sale Price' in training_data.columns # check that \"Sale Price\" is still in the training_data table\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> 'Log Sale Price' in training_data.columns\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(training_data['Log Sale Price'].sum(), 2055590.7351105125, atol=0.00001)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3a": {
     "name": "q3a",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> q3statement in [True, False]\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3b": {
     "name": "q3b",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> 'Building Square Feet' in training_data.columns  #check that \"Building Square Feet\" is still in the training_data table\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> 'Log Building Square Feet' in training_data.columns\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(training_data['Log Building Square Feet'].mean(), 7.2914293261161)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> \n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # Make sure that remove_outliers doesn't mutate its input\n>>> remove_outliers(training_data, 'Building Square Feet', upper=2000).shape != training_data.shape\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5a": {
     "name": "q5a",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(q5a, list) == True\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> isinstance(q5a[0], int) == True\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5b": {
     "name": "q5b",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> not training_data['Bedrooms'].isnull().any() # Check that missing values are dealt with\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> pd.api.types.is_integer_dtype(training_data['Bedrooms']) # Check that Bedrooms are ints\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6a": {
     "name": "q6a",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(num_neighborhoods, int)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6b": {
     "name": "q6b",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> len(in_top_20_neighborhoods['Neighborhood Code'].unique()) == 20\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> in_top_20_neighborhoods['Neighborhood Code'].iloc[0] == 120\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6c": {
     "name": "q6c",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> len(find_expensive_neighborhoods(training_data, 5, np.median)) == 5\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> isinstance(expensive_neighborhoods, list)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> set(find_expensive_neighborhoods(training_data, 2, np.min)) == set([106, 580])\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6d": {
     "name": "q6d",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> (sum(training_data.loc[:, 'in_expensive_neighborhood']) == 1290) and (sum(training_data.loc[:, 'in_expensive_neighborhood'].isnull()) == 0)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7a": {
     "name": "q7a",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> set(training_data_mapped['Roof Material'].unique()) == set(['Shingle/Asphalt', 'Tar & Gravel', 'Other', 'Tile', 'Shake', 'Slate'])\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7b": {
     "name": "q7b",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> training_data_ohe.shape == (168931, 72)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> expected_ohe_cols = set(['Roof Material_Other', 'Roof Material_Shake', 'Roof Material_Shingle/Asphalt' ,'Roof Material_Slate', 'Roof Material_Tar & Gravel', 'Roof Material_Tile'])\n>>> expected_ohe_cols.issubset(set(training_data_ohe.columns)) == True\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
